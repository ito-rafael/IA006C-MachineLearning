{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input_cols = ['NO_MUNICIPIO_RESIDENCIA', 'SG_UF_RESIDENCIA', 'NU_IDADE', 'TP_SEXO', 'TP_ESTADO_CIVIL',\n",
    "    'TP_COR_RACA', 'TP_NACIONALIDADE', 'NO_MUNICIPIO_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ST_CONCLUSAO',\n",
    "    'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO', 'IN_TREINEIRO', 'NO_MUNICIPIO_ESC',\n",
    "    'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC', 'IN_BAIXA_VISAO',\n",
    "    'IN_CEGUEIRA', 'IN_SURDEZ', 'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA', 'IN_DEFICIENCIA_FISICA',\n",
    "    'IN_DEFICIENCIA_MENTAL', 'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA', 'IN_AUTISMO',\n",
    "    'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE', 'IN_LACTANTE', 'IN_IDOSO', 'IN_ESTUDA_CLASSE_HOSPITALAR',\n",
    "    'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18', 'IN_LEDOR', 'IN_ACESSO', 'IN_TRANSCRICAO',\n",
    "    'IN_LIBRAS', 'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS', 'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA',\n",
    "    'IN_GUIA_INTERPRETE', 'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO', 'IN_CADEIRA_ACOLCHOADA',\n",
    "    'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO', 'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE',\n",
    "    'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA', 'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL',\n",
    "    'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO', 'IN_MATERIAL_ESPECIFICO', 'IN_NOME_SOCIAL', 'NO_MUNICIPIO_PROVA',\n",
    "    'SG_UF_PROVA', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT',\n",
    "    'TP_LINGUA',  'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014',\n",
    "    'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022', 'Q023', 'Q024', 'Q025', 'Q026', 'Q027']\n",
    "'''\n",
    "input_cols = ['SG_UF_RESIDENCIA', 'NU_IDADE', 'TP_SEXO', 'TP_ESTADO_CIVIL',\n",
    "    'TP_COR_RACA', 'TP_NACIONALIDADE', 'SG_UF_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO', 'TP_ST_CONCLUSAO',\n",
    "    'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO', 'IN_TREINEIRO',\n",
    "    'IN_BAIXA_VISAO',\n",
    "    'IN_CEGUEIRA', 'IN_SURDEZ', 'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA', 'IN_DEFICIENCIA_FISICA',\n",
    "    'IN_DEFICIENCIA_MENTAL', 'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA', 'IN_AUTISMO',\n",
    "    'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE', 'IN_LACTANTE', 'IN_IDOSO',\n",
    "    'IN_ESTUDA_CLASSE_HOSPITALAR',\n",
    "    'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18', 'IN_LEDOR',\n",
    "    'IN_ACESSO', 'IN_TRANSCRICAO',\n",
    "    'IN_LIBRAS', 'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS', 'IN_MESA_CADEIRA_SEPARADA',\n",
    "    'IN_APOIO_PERNA',\n",
    "    'IN_GUIA_INTERPRETE', 'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO',\n",
    "    'IN_CADEIRA_ACOLCHOADA',\n",
    "    'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO', 'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE',\n",
    "    'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA', 'IN_MEDICAMENTOS',\n",
    "    'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL',\n",
    "    'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO', 'IN_MATERIAL_ESPECIFICO',\n",
    "    'IN_NOME_SOCIAL',\n",
    "    'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT',\n",
    "    'TP_LINGUA',  'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008',\n",
    "      'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014',\n",
    "    'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022', 'Q023',\n",
    "      'Q024', 'Q025', 'Q026', 'Q027']\n",
    "\n",
    "output_cols = ['NU_NOTA_REDACAO','NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from os.path import abspath, join\n",
    "\n",
    "root_dir = abspath('..')\n",
    "dataset_dir = join(root_dir, 'dataset')\n",
    "# set dataset files path\n",
    "file_path = join(dataset_dir, 'microdados_enem2018.zip')\n",
    "# read zip files\n",
    "zf = zipfile.ZipFile(file_path)\n",
    "data = pandas.read_csv(zf.open('DADOS/MICRODADOS_ENEM_2018.csv'),\n",
    "                       sep=';', encoding='cp1252', usecols=input_cols + output_cols)\\\n",
    "            .dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DADOS DO QUESTIONÁRIO SOCIOECONÔMICO\n",
    "\n",
    "* Q001,Q002                  A-H\n",
    "* Q003,Q004                  A-F\n",
    "* Q005                       1-20 (Numérico)\n",
    "* Q006                       A-Q \n",
    "* Q007,Q026                  A-D\n",
    "* Q008-17,Q019,Q022,Q024     A-E\n",
    "* Q018,Q020-21,Q023,Q025     A-B  (Encode A=0, B=1)\n",
    "* Q027                       A-F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_socio = ['Q001','Q002','Q003','Q004','Q006',\n",
    "         'Q007','Q008','Q009','Q010','Q011','Q012','Q013','Q014',\n",
    "         'Q015','Q016','Q017','Q019','Q022','Q024','Q026','Q027',\n",
    "        ]\n",
    "encode_socio = {\n",
    "    'Q018':{'A':0,'B':1},\n",
    "    'Q020':{'A':0,'B':1},\n",
    "    'Q021':{'A':0,'B':1},\n",
    "    'Q023':{'A':0,'B':1},\n",
    "    'Q025':{'A':0,'B':1}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DADOS DA ESCOLA \n",
    "* NO_MUNICIPIO_ESC\tNome do município da escola\n",
    "* SG_UF_ESC\tSigla da Unidade da Federação da escola\n",
    "* TP_DEPENDENCIA_ADM_ESC\tDependência administrativa (Escola) 1-4\n",
    "* TP_LOCALIZACAO_ESC\tLocalização (Escola) 1-2\n",
    "* TP_SIT_FUNC_ESC\tSituação de funcionamento (Escola) 1-3\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_escola = ['NO_MUNICIPIO_ESC','SG_UF_ESC','TP_DEPENDENCIA_ADM_ESC','TP_LOCALIZACAO_ESC','TP_SIT_FUNC_ESC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DADOS DO LOCAL DE APLICAÇÃO DA PROVA\n",
    "* NO_MUNICIPIO_PROVA\tNome do município da aplicação da prova\n",
    "* SG_UF_PROVA\tSigla da Unidade da Federação da aplicação da prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_loc_prova = ['NO_MUNICIPIO_PROVA','SG_UF_PROVA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DADOS DO PARTICIPANTE\t\n",
    "* NO_MUNICIPIO_RESIDENCIA\tNome do município de residência \n",
    "* SG_UF_RESIDENCIA\tSigla da Unidade da Federação de residência\n",
    "* NU_IDADE\tIdade\n",
    "* TP_SEXO\tSexo\n",
    "* TP_ESTADO_CIVIL\tEstado Civil\n",
    "* TP_COR_RACA\tCor/raça\n",
    "* TP_NACIONALIDADE\tNacionalidade\n",
    "* NO_MUNICIPIO_NASCIMENTO\tNome do município de nascimento \n",
    "* SG_UF_NASCIMENTO\tSigla da Unidade da Federação de nascimento\n",
    "* TP_ST_CONCLUSAO\tSituação de conclusão do Ensino Médio\n",
    "* TP_ANO_CONCLUIU\tAno de Conclusão do Ensino Médio 1-12\n",
    "* TP_ESCOLA\tTipo de escola do Ensino Médio 1-4\n",
    "* TP_ENSINO\tTipo de instituição que concluiu ou concluirá o Ensino Médio 1-3\n",
    "* IN_TREINEIRO\tIndica se o inscrito fez a prova com intuito de apenas treinar seus conhecimentos 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_participante = [\n",
    "    'NO_MUNICIPIO_RESIDENCIA','SG_UF_RESIDENCIA','NU_IDADE',\n",
    "    'TP_ESTADO_CIVIL','TP_COR_RACA','NO_MUNICIPIO_NASCIMENTO',\n",
    "    'SG_UF_NASCIMENTO','TP_NACIONALIDADE',\n",
    "    'TP_ST_CONCLUSAO','TP_ANO_CONCLUIU','TP_ESCOLA','TP_ENSINO','IN_TREINEIRO'\n",
    "]\n",
    "\n",
    "encode_participante = {'TP_SEXO':{'M':0, 'F':1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DADOS DA PROVA OBJETIVA\t\n",
    "* TP_PRESENCA_CN\tPresença na prova objetiva de Ciências da Natureza\n",
    "* TP_PRESENCA_CH\tPresença na prova objetiva de Ciências Humanas\n",
    "* TP_PRESENCA_LC\tPresença na prova objetiva de Linguagens e Códigos\n",
    "* TP_PRESENCA_MT\tPresença na prova objetiva de Matemática\n",
    "\n",
    "Aplicando a seguinte conversão:\n",
    "\n",
    "encode_nota\n",
    "\n",
    "Conceito|Faixa de nota correspondente\n",
    "------------|-------------------------\n",
    "A \t| Entre 900 e 1000 \n",
    "B \t| Entre 700 e 899 \n",
    "C \t| Entre 500 e 699\n",
    "D \t| Entre 450 e 499\n",
    "F \t| Abaixo de 450\n",
    "\n",
    "\n",
    "encode_nota_2\n",
    "\n",
    "Conceito|Faixa de nota correspondente\n",
    "------------|-------------------------\n",
    "A \t| Entre 600 e 1000\n",
    "B \t| Entre 450 e 600\n",
    "C \t| Abaixo de 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_prova = ['TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_nota(val):\n",
    "    if val >= 900:\n",
    "        return 'A'\n",
    "    elif val >= 700 and val < 900:\n",
    "        return 'B'\n",
    "    elif val >= 500 and val < 700:\n",
    "        return 'C'\n",
    "    elif val >= 450 and val < 500:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'F'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_nota_2(val):\n",
    "    if val >= 600:\n",
    "        return 'A'\n",
    "    elif val >= 450 and val < 600:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtragem do DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataframe\n",
    "# Se for apenas um treino(prova) não usar..\n",
    "data = data[data['IN_TREINEIRO']==0].drop(['IN_TREINEIRO'], axis=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estou interessado em uma visão geral da nota do aluno\n",
    "Se por algum motivo ele não fez a prova o dado não é válido para mim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape (2247250, 99)\n",
      "Filtering TP_PRESENCA_CN\n",
      "Filtering TP_PRESENCA_CH\n",
      "Filtering TP_PRESENCA_LC\n",
      "Filtering TP_PRESENCA_MT\n",
      "Final shape (2247250, 95)\n"
     ]
    }
   ],
   "source": [
    "print('Initial shape {}'.format(data.shape))\n",
    "for p in ['TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT']:\n",
    "    if p in data.columns:\n",
    "        data = data[data[p]==1].drop([p], axis=1)\n",
    "        print('Filtering {}'.format(p))\n",
    "    else:\n",
    "        print('Columns {} do not exists.'.format(p))\n",
    "print('Final shape {}'.format(data.shape))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nota média total\n",
    "data['NU_NOTA_TOTAL'] = (data['NU_NOTA_REDACAO'] + data['NU_NOTA_CN'] +\\\n",
    "                         data['NU_NOTA_CH'] + data['NU_NOTA_LC'] + data['NU_NOTA_MT'])/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fa61031b588>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa610393358>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fa61043dc88>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa610474a90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fa6104ab860>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa6104db4a8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[['NU_NOTA_REDACAO','NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT','NU_NOTA_TOTAL']].hist(bins=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_hot_cols = one_hot_socio+one_hot_escola+one_hot_loc_prova+one_hot_participante+one_hot_prova\n",
    "\n",
    "df_inp = pandas.get_dummies(data[set(input_cols).intersection(data.columns)], \n",
    "                   columns=set(one_hot_cols).intersection(set(input_cols)).intersection(set(data.columns))\n",
    "           ).replace({**encode_participante, **encode_socio})\n",
    "\n",
    "#df_out = data[output_cols]\n",
    "df_out = pandas.get_dummies(data['NU_NOTA_TOTAL'].apply(encode_nota_2))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train', (1348349, 5591), (1348349, 3))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inp_train, df_inp_test, df_out_train, df_out_test = \\\n",
    "    train_test_split(df_inp,df_out, test_size=0.25, random_state=1)\n",
    "\n",
    "df_inp_train, df_inp_val, df_out_train, df_out_val = \\\n",
    "    train_test_split(df_inp_train, df_out_train, test_size=0.20, random_state=1)\n",
    "\n",
    "for col in df_inp.columns:\n",
    "    if df_inp[col].dtype != 'uint8' and df_inp[col].dtype != 'int64':\n",
    "        print(col, df_inp[col].dtype)\n",
    "        \n",
    "'Train', df_inp_train.shape, df_out_train.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train', (639657, 387), (639657, 3))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(neurons=30, kernel_initializer='uniform'):\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(neuron_num, input_dim=2, activity_regularizer=l1_l2(0.01, 0.01)))\n",
    "\n",
    "    # Camada Entrada\n",
    "    model.add(Dense(neurons, input_dim=df_inp_train.shape[1], kernel_initializer=kernel_initializer))\n",
    "    model.add(Activation('relu'))\n",
    " \n",
    "    model.add(Dense(neurons, kernel_initializer=kernel_initializer))\n",
    "    model.add(Activation('relu'))\n",
    "  \n",
    "    # Camada Saída\n",
    "    model.add(Dense(df_out_train.shape[1], kernel_initializer=kernel_initializer))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Neuron Numbers on 3 layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp_train, df_inp_test, df_out_train, df_out_test = \\\n",
    "    train_test_split(df_inp,df_out, test_size=0.25, random_state=1)\n",
    "\n",
    "df_inp_train, df_inp_val, df_out_train, df_out_val = \\\n",
    "    train_test_split(df_inp_train, df_out_train, test_size=0.20, random_state=1)\n",
    "\n",
    "for col in df_inp.columns:\n",
    "    if df_inp[col].dtype != 'uint8' and df_inp[col].dtype != 'int64':\n",
    "        print(col, df_inp[col].dtype)\n",
    "        \n",
    "'Train', df_inp_train.shape, df_out_train.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 72 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  40 | elapsed:  4.3min remaining:  4.3min\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-01b830dc1d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m grid = GridSearchCV(estimator=keras_model, param_grid=param_grid,\n\u001b[1;32m      7\u001b[0m                     verbose=1,n_jobs=-1, cv=5, scoring='f1_macro')\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_out_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "# create model \n",
    "keras_model = KerasClassifier(build_fn=get_model, epochs=50, batch_size=50, verbose=0)\n",
    "# define the grid search parameters\n",
    "neurons = [10, 20, 60, 100, 150, 200, 300, 500]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=keras_model, param_grid=param_grid,\n",
    "                    verbose=1,n_jobs=-1, cv=5, scoring='f1_macro')\n",
    "grid_result = grid.fit(df_inp_train, df_out_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 639657 samples, validate on 159915 samples\n",
      "Epoch 1/50\n",
      "639657/639657 [==============================] - 15s 24us/step - loss: 0.7617 - val_loss: 0.7331\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.89742 to 0.73306, saving model to mlp-w\n",
      "Epoch 2/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.7283 - val_loss: 0.7293\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.73306 to 0.72931, saving model to mlp-w\n",
      "Epoch 3/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.7237 - val_loss: 0.7268\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.72931 to 0.72676, saving model to mlp-w\n",
      "Epoch 4/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: 0.7209 - val_loss: 0.7291\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.72676\n",
      "Epoch 5/50\n",
      "639657/639657 [==============================] - 17s 27us/step - loss: 0.7192 - val_loss: 0.7260\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.72676 to 0.72597, saving model to mlp-w\n",
      "Epoch 6/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.7172 - val_loss: 0.7256\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.72597 to 0.72555, saving model to mlp-w\n",
      "Epoch 7/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.7156 - val_loss: 0.7261\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.72555\n",
      "Epoch 8/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.7141 - val_loss: 0.7257\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.72555\n",
      "Epoch 9/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.7127 - val_loss: 0.7257\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.72555\n",
      "Epoch 10/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.7111 - val_loss: 0.7268\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.72555\n",
      "Epoch 11/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.7098 - val_loss: 0.7298\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.72555\n",
      "Epoch 12/50\n",
      "639657/639657 [==============================] - 15s 24us/step - loss: 0.7082 - val_loss: 0.7289\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.72555\n",
      "Epoch 13/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.7068 - val_loss: 0.7305\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.72555\n",
      "Epoch 14/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.7055 - val_loss: 0.7331\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.72555\n",
      "Epoch 15/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.7044 - val_loss: 0.7316\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.72555\n",
      "Epoch 16/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.7025 - val_loss: 0.7328\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.72555\n",
      "Epoch 17/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.7005 - val_loss: 0.7335\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.72555\n",
      "Epoch 18/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.6991 - val_loss: 0.7345\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.72555\n",
      "Epoch 19/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.6977 - val_loss: 0.7351\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.72555\n",
      "Epoch 20/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.6958 - val_loss: 0.7375\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.72555\n",
      "Epoch 21/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: 0.6940 - val_loss: 0.7397\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.72555\n",
      "Epoch 22/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.6927 - val_loss: 0.7401\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.72555\n",
      "Epoch 23/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.6908 - val_loss: 0.7425\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.72555\n",
      "Epoch 24/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: 0.6890 - val_loss: 0.7422\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.72555\n",
      "Epoch 25/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: 0.6872 - val_loss: 0.7441\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.72555\n",
      "Epoch 26/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.6852 - val_loss: 0.7464\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.72555\n",
      "Epoch 27/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.6837 - val_loss: 0.7471\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.72555\n",
      "Epoch 28/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.6820 - val_loss: 0.7504\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.72555\n",
      "Epoch 29/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: 0.6796 - val_loss: 0.7497\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.72555\n",
      "Epoch 30/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.6782 - val_loss: 0.7522\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.72555\n",
      "Epoch 31/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: 0.6763 - val_loss: 0.7547\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.72555\n",
      "Epoch 32/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.6750 - val_loss: 0.7567\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.72555\n",
      "Epoch 33/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: 0.6725 - val_loss: 0.7581\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.72555\n",
      "Epoch 34/50\n",
      "639657/639657 [==============================] - 16s 24us/step - loss: 0.6710 - val_loss: 0.7610\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.72555\n",
      "Epoch 35/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.6698 - val_loss: 0.7619\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.72555\n",
      "Epoch 36/50\n",
      "639657/639657 [==============================] - 15s 24us/step - loss: 0.6678 - val_loss: 0.7633\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.72555\n",
      "Epoch 37/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.6660 - val_loss: 0.7637\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.72555\n",
      "Epoch 38/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.6645 - val_loss: 0.7672\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.72555\n",
      "Epoch 39/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: 0.6630 - val_loss: 0.7688\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.72555\n",
      "Epoch 40/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: 0.6615 - val_loss: 0.7702\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.72555\n",
      "Epoch 41/50\n",
      "639657/639657 [==============================] - 15s 24us/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.72555\n",
      "Epoch 42/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.72555\n",
      "Epoch 43/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.72555\n",
      "Epoch 44/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.72555\n",
      "Epoch 45/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.72555\n",
      "Epoch 46/50\n",
      "639657/639657 [==============================] - 16s 26us/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.72555\n",
      "Epoch 47/50\n",
      "639657/639657 [==============================] - 17s 26us/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.72555\n",
      "Epoch 48/50\n",
      "639657/639657 [==============================] - 16s 25us/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.72555\n",
      "Epoch 49/50\n",
      "230000/639657 [=========>....................] - ETA: 9s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-feb4e060f050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf_inp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_out_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inp_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_out_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     epochs=50, batch_size=5000, verbose=1, shuffle=True, use_multiprocessing=True)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    184\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint('mlp-neurons-{}-init-{}'.format(neurons,kernel_initializer),\n",
    "                    monitor='val_loss', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# we'll use categorical xent for the loss, and RMSprop as the optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#if os.path.isfile(mlp_weight):\n",
    "#    model.load_weights(mlp_weight)\n",
    "print(\"Training...\")\n",
    "history = model.fit(\\\n",
    "    df_inp_train, df_out_train, validation_data=(df_inp_val, df_out_val),\\\n",
    "    callbacks=callbacks,\\\n",
    "    epochs=50, batch_size=5000, verbose=1, shuffle=True, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.grid(color='#919191', linestyle=':', linewidth=1)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "fig.savefig('mlp_history.png', dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "639657/639657 [==============================] - 60s 93us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.85      0.90      0.87     19424\n",
      "           B       0.86      0.90      0.88     93305\n",
      "           C       0.85      0.89      0.87    238645\n",
      "           D       0.65      0.92      0.76     24237\n",
      "           F       0.93      0.83      0.88    264046\n",
      "\n",
      "   micro avg       0.87      0.87      0.87    639657\n",
      "   macro avg       0.83      0.89      0.85    639657\n",
      "weighted avg       0.88      0.87      0.87    639657\n",
      " samples avg       0.87      0.87      0.87    639657\n",
      "\n",
      "TEST\n",
      "266524/266524 [==============================] - 25s 93us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.18      0.16      6721\n",
      "           B       0.31      0.32      0.31     39649\n",
      "           C       0.42      0.43      0.42    101842\n",
      "           D       0.03      0.06      0.04      7276\n",
      "           F       0.54      0.49      0.51    111036\n",
      "\n",
      "   micro avg       0.42      0.42      0.42    266524\n",
      "   macro avg       0.29      0.29      0.29    266524\n",
      "weighted avg       0.44      0.42      0.43    266524\n",
      " samples avg       0.42      0.42      0.42    266524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0–caminhada; 1 –subindoescadas; 2 –descendo escadas; 3 –sentado; 4 –em pé; 5 –deitado.\n",
    "print('TRAIN')\n",
    "pred = np_utils.to_categorical(model.predict_classes(df_inp_train, verbose=1))\n",
    "print(classification_report(\\\n",
    "    pred, df_out_train,\n",
    "    labels=range(5),\n",
    "    target_names=['A','B','C','D','F']))\n",
    "\n",
    "print('TEST')\n",
    "pred = np_utils.to_categorical(model.predict_classes(df_inp_test, verbose=1))\n",
    "print(classification_report(\\\n",
    "    pred, df_out_test,\n",
    "    labels=range(5),\n",
    "    target_names=['A','B','C','D','F']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_utils.to_categorical(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SG_UF_RESIDENCIA</th>\n",
       "      <th>NU_IDADE</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <th>TP_NACIONALIDADE</th>\n",
       "      <th>SG_UF_NASCIMENTO</th>\n",
       "      <th>TP_ST_CONCLUSAO</th>\n",
       "      <th>TP_ANO_CONCLUIU</th>\n",
       "      <th>TP_ESCOLA</th>\n",
       "      <th>...</th>\n",
       "      <th>Q018</th>\n",
       "      <th>Q019</th>\n",
       "      <th>Q020</th>\n",
       "      <th>Q021</th>\n",
       "      <th>Q022</th>\n",
       "      <th>Q023</th>\n",
       "      <th>Q024</th>\n",
       "      <th>Q025</th>\n",
       "      <th>Q026</th>\n",
       "      <th>Q027</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CE</td>\n",
       "      <td>19.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>CE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CE</td>\n",
       "      <td>18.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>CE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PB</td>\n",
       "      <td>18.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PB</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PI</td>\n",
       "      <td>54.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>PI</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SP</td>\n",
       "      <td>17.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513724</th>\n",
       "      <td>SP</td>\n",
       "      <td>18.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513730</th>\n",
       "      <td>RJ</td>\n",
       "      <td>18.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RJ</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513736</th>\n",
       "      <td>AM</td>\n",
       "      <td>18.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>AM</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513743</th>\n",
       "      <td>AM</td>\n",
       "      <td>20.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>AM</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513745</th>\n",
       "      <td>SP</td>\n",
       "      <td>17.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1066096 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SG_UF_RESIDENCIA  NU_IDADE TP_SEXO  TP_ESTADO_CIVIL  TP_COR_RACA  \\\n",
       "8                     CE      19.0       M              0.0            3   \n",
       "16                    CE      18.0       M              0.0            3   \n",
       "26                    PB      18.0       F              0.0            1   \n",
       "29                    PI      54.0       F              1.0            3   \n",
       "39                    SP      17.0       F              0.0            1   \n",
       "...                  ...       ...     ...              ...          ...   \n",
       "5513724               SP      18.0       M              0.0            1   \n",
       "5513730               RJ      18.0       M              0.0            3   \n",
       "5513736               AM      18.0       M              0.0            3   \n",
       "5513743               AM      20.0       F              0.0            3   \n",
       "5513745               SP      17.0       F              0.0            1   \n",
       "\n",
       "         TP_NACIONALIDADE SG_UF_NASCIMENTO  TP_ST_CONCLUSAO  TP_ANO_CONCLUIU  \\\n",
       "8                       1               CE                2                0   \n",
       "16                      1               CE                2                0   \n",
       "26                      1               PB                2                0   \n",
       "29                      1               PI                2                0   \n",
       "39                      1               SP                2                0   \n",
       "...                   ...              ...              ...              ...   \n",
       "5513724                 1               PE                2                0   \n",
       "5513730                 1               RJ                2                0   \n",
       "5513736                 1               AM                2                0   \n",
       "5513743                 1               AM                2                0   \n",
       "5513745                 1               SP                2                0   \n",
       "\n",
       "         TP_ESCOLA  ...  Q018  Q019 Q020  Q021  Q022  Q023  Q024  Q025  Q026  \\\n",
       "8                2  ...     A     B    B     A     B     A     A     A     B   \n",
       "16               2  ...     A     C    B     B     C     A     A     A     B   \n",
       "26               2  ...     A     B    A     A     D     A     A     B     B   \n",
       "29               2  ...     A     B    B     A     B     A     A     A     B   \n",
       "39               2  ...     B     B    B     A     D     B     B     B     B   \n",
       "...            ...  ...   ...   ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "5513724          2  ...     A     C    A     B     D     B     A     B     B   \n",
       "5513730          2  ...     A     B    B     A     E     A     B     B     B   \n",
       "5513736          2  ...     A     B    A     A     E     A     B     B     B   \n",
       "5513743          2  ...     A     A    A     A     B     A     A     B     B   \n",
       "5513745          4  ...     B     C    B     B     E     A     C     B     B   \n",
       "\n",
       "         Q027  \n",
       "8           A  \n",
       "16          A  \n",
       "26          A  \n",
       "29          A  \n",
       "39          A  \n",
       "...       ...  \n",
       "5513724     A  \n",
       "5513730     A  \n",
       "5513736     A  \n",
       "5513743     A  \n",
       "5513745     C  \n",
       "\n",
       "[1066096 rows x 104 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
